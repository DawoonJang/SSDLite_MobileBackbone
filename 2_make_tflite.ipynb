{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from model.ModelBuilder import ModelBuilder\n",
    "from utils_train.Datagenerator import AnchorBox\n",
    "\n",
    "\n",
    "from object_detection.core import post_processing\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"MobileNetV3_PFH_SSD\"\n",
    "    \n",
    "model_dir = \"checkpoints/\"\n",
    "modelPart = modelName.split(\"_\")\n",
    "\n",
    "with open(os.path.join(\"model\", \"0_Config\", modelName+\".json\"), \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "config['modelName'] = modelName\n",
    "config['training_config']['num_classes'] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelBuilder(config = config)\n",
    "#model.load_weights(\"logs/_epoch190_mAP0.228\").expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MAX_CLASSES_PER_DETECTION = 1\n",
    "_DETECTION_POSTPROCESS_FUNC = 'TFLite_Detection_PostProcess'\n",
    "\n",
    "\n",
    "class SSDModule(tf.Module):\n",
    "    \"\"\"Inference Module for TFLite-friendly SSD models.\"\"\"\n",
    "    def __init__(self, config, detection_model, max_detections=100, use_regular_nms=False):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "          pipeline_config: The original pipeline_pb2.TrainEvalPipelineConfig\n",
    "          detection_model: The detection model to use for inference.\n",
    "          max_detections: Max detections desired from the TFLite model.\n",
    "          use_regular_nms: If True, TFLite model uses the (slower) multi-class NMS.\n",
    "        \"\"\"\n",
    "        self._process_config(config)\n",
    "        self._model = detection_model\n",
    "        self._max_detections = max_detections\n",
    "        self._use_regular_nms = use_regular_nms\n",
    "        self._Anchors =  AnchorBox(config).get_anchors()\n",
    "\n",
    "    def _process_config(self, config):\n",
    "        self._num_classes = config['training_config']['num_classes']\n",
    "        self._nms_score_threshold=0.3\n",
    "        self._nms_iou_threshold=0.6\n",
    "        self._scale_values = {}\n",
    "        self._scale_values['y_scale']=10.0\n",
    "        self._scale_values['x_scale']=10.0\n",
    "        self._scale_values['h_scale']=5.0\n",
    "        self._scale_values['w_scale']=5.0\n",
    "\n",
    "    def input_shape(self):\n",
    "        \"\"\"Returns shape of TFLite model input.\"\"\"\n",
    "        return [1, config[\"model_config\"][\"target_size\"], config[\"model_config\"][\"target_size\"], 3]\n",
    "\n",
    "    def postprocess_implements_signature(self):\n",
    "        \"\"\"Returns tf.implements signature for MLIR legalization of TFLite NMS.\"\"\"\n",
    "        implements_signature = [\n",
    "            'name: \"%s\"' % _DETECTION_POSTPROCESS_FUNC,\n",
    "            'attr { key: \"max_detections\" value { i: %d } }' % self._max_detections,\n",
    "            'attr { key: \"max_classes_per_detection\" value { i: %d } }' %\n",
    "            _MAX_CLASSES_PER_DETECTION,\n",
    "            'attr { key: \"use_regular_nms\" value { b: %s } }' %\n",
    "            str(self._use_regular_nms).lower(),\n",
    "            'attr { key: \"nms_score_threshold\" value { f: %f } }' %\n",
    "            self._nms_score_threshold,\n",
    "            'attr { key: \"nms_iou_threshold\" value { f: %f } }' %\n",
    "            self._nms_iou_threshold,\n",
    "            'attr { key: \"y_scale\" value { f: %f } }' %\n",
    "            self._scale_values['y_scale'],\n",
    "            'attr { key: \"x_scale\" value { f: %f } }' %\n",
    "            self._scale_values['x_scale'],\n",
    "            'attr { key: \"h_scale\" value { f: %f } }' %\n",
    "            self._scale_values['h_scale'],\n",
    "            'attr { key: \"w_scale\" value { f: %f } }' %\n",
    "            self._scale_values['w_scale'],\n",
    "            'attr { key: \"num_classes\" value { i: %d } }' % self._num_classes\n",
    "        ]\n",
    "        implements_signature = ' '.join(implements_signature)\n",
    "        return implements_signature\n",
    "\n",
    "    def _get_postprocess_fn(self, num_anchors, num_classes):\n",
    "        # There is no TF equivalent for TFLite's custom post-processing op.\n",
    "        # So we add an 'empty' composite function here, that is legalized to the\n",
    "        # custom op with MLIR.\n",
    "        @tf.function(experimental_implements=self.postprocess_implements_signature())\n",
    "\n",
    "        def dummy_post_processing(box_encodings, class_predictions, anchors):\n",
    "            boxes = tf.constant(0.0, dtype=tf.float32, name='boxes')\n",
    "            scores = tf.constant(0.0, dtype=tf.float32, name='scores')\n",
    "            classes = tf.constant(0.0, dtype=tf.float32, name='classes')\n",
    "            num_detections = tf.constant(0.0, dtype=tf.float32, name='num_detections')\n",
    "            return boxes, classes, scores, num_detections\n",
    "\n",
    "        return dummy_post_processing\n",
    "\n",
    "    @tf.function\n",
    "    def inference_fn(self, image):\n",
    "        \"\"\"Encapsulates SSD inference for TFLite conversion.\n",
    "\n",
    "        NOTE: The Args & Returns sections below indicate the TFLite model signature,\n",
    "        and not what the TF graph does (since the latter does not include the custom\n",
    "        NMS op used by TFLite)\n",
    "\n",
    "        Args:\n",
    "          image: a float32 tensor of shape [num_anchors, 4] containing the anchor\n",
    "            boxes\n",
    "\n",
    "        Returns:\n",
    "          num_detections: a float32 scalar denoting number of total detections.\n",
    "          classes: a float32 tensor denoting class ID for each detection.\n",
    "          scores: a float32 tensor denoting score for each detection.\n",
    "          boxes: a float32 tensor denoting coordinates of each detected box.\n",
    "        \"\"\"\n",
    "        predicted_tensors = self._model(image)\n",
    "        class_predictions = tf.sigmoid(predicted_tensors['ClfPred'])\n",
    "        class_predictions = tf.identity(class_predictions, name='class_predictions')\n",
    "\n",
    "        box_encodings = tf.identity(predicted_tensors[\"BoxPred\"], name='box_encodings')\n",
    "\n",
    "        anchors = tf.identity(self._Anchors, name='anchors')\n",
    "\n",
    "        # tf.function@ seems to reverse order of inputs, so reverse them here.\n",
    "        return self._get_postprocess_fn(detection_module._Anchors.shape[0], self._num_classes)(box_encodings, class_predictions, anchors)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_module = SSDModule(config, model)    \n",
    "concrete_function = detection_module.inference_fn.get_concrete_function(tf.TensorSpec(shape=detection_module.input_shape(), dtype=tf.float32, name='input'))\n",
    "tf.saved_model.save(detection_module, \"logs/tflite_Test\", signatures=concrete_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimated count of arithmetic ops:325.369 M  ops, equivalently 162.684 M  MACs MB3 PFH\n",
    "#Estimated count of arithmetic ops:494.661 M  ops, equivalently 247.331 M  MACs MB3 FPN\n",
    "\n",
    "#Estimated count of arithmetic ops: 77.080 G  ops, equivalently 38.540 G  MACs\n",
    "\n",
    "#Estimated count of arithmetic ops:905.699 M  ops, equivalently 452.849 M  MACs MBDet PFH\n",
    "#Estimated count of arithmetic ops: 1.121 G  ops, equivalently 0.560 G  MACs MBDet FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"logs/tflite_Test\", signature_keys=['serving_default'])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "#converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "with tf.io.gfile.GFile('converted_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as  tfds\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    [test_dataset], dataset_info = tfds.load(name=\"coco/2017\", split=[\"validation\"], with_info=True)\n",
    "    HEIGHT, WIDTH = 320, 320\n",
    "    for sample in test_dataset.take(100):\n",
    "        img = sample['image']\n",
    "        resized_img = tf.image.resize(img, (HEIGHT, WIDTH))\n",
    "        resized_img = tf.cast(resized_img /127.5 -1.0, tf.float32)\n",
    "        resized_img = tf.expand_dims(resized_img, 0)\n",
    "        yield [resized_img]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"logs/tflite_Test\", signature_keys=['serving_default'])\n",
    "\n",
    "\n",
    "converter.allow_custom_ops = True\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "'''\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS\n",
    "]\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "'''\n",
    "\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.quantized_input_stats = {\"normalized_input_image_tensor\": (128, 128)}\n",
    "#converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "#with open('converted_model.tflite', 'wb') as f:\n",
    "with tf.io.gfile.GFile('converted_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd95acf9ab06b1ecf423b431b914fca015df3a9e640117d0d3acee71022bc47"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('w1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
